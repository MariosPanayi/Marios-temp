#  Order data
A = data.frame(time, event, eventID)
A = setorder(A, time, eventID)
# Add a numeric order to the list so we can manipulate values later
A$eventorder = c(1:nrow(A))
view(A)
# Check for sequential times that are tied for more than 1 event
# N.B. if ties[i] = 0, then that event[i] and event[i+1] happened at the same time
ties = diff(A$time)
ties = which(ties == 0)
ties
(length(ties) != 0)
(ties[1] == 1)
j = 2
c(j:length(ties))
(length(ties) == 1 & ties[1] == 1)
length(ties) != 0
!(length(ties) == 1 & ties[1] == 1)
(length(ties) != 0 | !(length(ties) == 1 & ties[1] == 1))
(length(ties) != 0 | (!(length(ties) == 1 & ties[1] == 1)))
(length(ties) == 1 & ties[1] == 1)
(length(ties) != 1 ! ties[1] != 1)
(length(ties) == 1 & ties[1] == 1)
(!(length(ties) == 1 & ties[1] == 1))
(length(ties) != 0 | (!(length(ties) == 1 & ties[1] == 1)) )
(length(ties) != 0 | ((length(ties) == 1 & ties[1] == 1))
(length(ties) != 0 | ((length(ties) == 1 & ties[1] == 1)) )
((length(ties) == 1 & ties[1] == 1))
length(ties) != 1
(length(ties) != 1 & ties[1] != 1)
(length(ties) != 0 & ties[1] != 0)
(length(ties) != 2 & ties[1] != 2)
(length(ties) != 1 & ties[1] != 1)
(length(ties) > 1 & ties[1] > 1)
c(1:1)
# If there are ties to consider
if (length(ties) != 0) {
# Special case to ignore when there is only 1 tie AND it is the very first event
if (length(ties) > 1 & ties[1] > 1) {
# Test to ignore first tie if it is also the first event
if(ties[1] == 1) {j = 2} else {j = 1}
for(i in c(j:length(ties))){
idx = ties[i]
if((A$event[idx-1] == "A_on" & A$event[idx] == "A_on" &  A$event[idx+1] == "A_off")) {
# If the tied A_on and A_off signals are in the wrong order, switch them around
# Note that this is the only way they can be ordered incorrectly since:
# 1) We have already ordered the data so any times that are tied will put an A_on before an A_off
# 2) Coulbourn never records more than 1x A_on and 1x A_off with the same time
# 3) If the previous A_on had a simultaneous A_off then it would also be recorded as such
A$eventorder[idx] = idx+1
A$eventorder[idx+1] = idx
# Important to re-order the data after each change in case multiple ties are adjacent to each other
A = setorder(A, eventorder)
}
(ties[1] == 1)
source('~/GitHub/Marios-temp/NIDA_Expts/Experiments/MPNIDA001_Pilots/scripts/MasterProcessingScript_2_ConditionedReinforcement_TestSessions.R', echo=TRUE)
source('~/GitHub/Marios-temp/NIDA_Expts/Experiments/MPNIDA001_Pilots/scripts/Plot_2_CRF.R', echo=TRUE)
# Load Packagaes ----------------------------------------------------------
## Packages for data organisation and plotting
library(tidyverse)
library(knitr)
# Package for relative file paths
library(here)
# Load Analysis Functions
source(here("scripts", "CoulbournAnalysisFunctions.R"))
# Identify files to analyze
# Can't use here() function effectively here, so have to create relative file paths
## COllapses multiple subfolders if needed
datafoldersinproject1 <- c("rawdata")
datafoldersinproject2 <-c("Marios")
## Project specific folder
projectdatafolder <- c("3_LeverPressingForLights")
## Final level of folders contianing the relevant .txt Coulbourn files
listofdatafolders <- c("LPL_Reinstatement_Test_Day15")
#  extract data filenames, only .txt --------------------------------------
datafilepaths <-0
for (i in c(1:length(listofdatafolders))){
lookup <- paste(datafoldersinproject1, datafoldersinproject2, projectdatafolder, listofdatafolders[i], sep = "/")
datafilepaths <- list.files(path = lookup, pattern = ".txt")
for (j in c(1:length(datafilepaths))) {
# For each raw.txt file split up the data into indivudal subjects .csv files for subsequent analysis
folderpath <- here(datafoldersinproject1, datafoldersinproject2,projectdatafolder,listofdatafolders[i])
filename <- datafilepaths[j]
## Run Function
coulbourn_rawdatasplit(filename,folderpath)
}
#  extract processed data filenames, only .csv and put them into a --------
########## Set parameters ############
## List of states
S = c("Test_NonReinforced" = 1,
"ITI" = 2,
"Test_Reinforced" = 3,
"Flash" = 4,
"Steady" = 5,
"End" = 6)
## Time base the linc was set to, in ms
timebase = 20
## Time bins to analyze each state in, in s
timebinwidth = 60
## Count the frequency and duration of these states
bin = c(S["Flash"], S["Steady"])
## state that should be considered the end of the session. For the absolute end of recording specify the number -1 [the state_ID of the finished state in Coulbourn]
sessionendstate <- S["End"]
########## Run Analysis ############
for (i in c(1:length(listofdatafolders))){
lookup <- paste(datafoldersinproject1, datafoldersinproject2, projectdatafolder, listofdatafolders[i], sep = "/")
datafilepaths <- list.files(path = lookup, pattern = ".csv")
for (j in c(1:length(datafilepaths))) {
# For each raw.txt file split up the data into individudal subjects .csv files for subsequent analysis
folderpath <- here(datafoldersinproject1, datafoldersinproject2,projectdatafolder,listofdatafolders[i])
filename <- datafilepaths[j]
## Run Function - N.B. Warnings will appear to tell you that the new directory for data storage already exists. Safe to ignore.
coulbourn_processdata_Operant_SessionTimeBinAnalysis(filename,folderpath,S,timebase, timebinwidth, bin, sessionendstate)
}
warnings()
dir.create(savefolderpath, showWarnings = FALSE)
for (i in c(1:length(listofdatafolders))){
lookup <- paste(datafoldersinproject1, datafoldersinproject2, projectdatafolder, listofdatafolders[i], sep = "/")
datafilepaths <- list.files(path = lookup, pattern = ".csv")
for (j in c(1:length(datafilepaths))) {
# For each raw.txt file split up the data into individudal subjects .csv files for subsequent analysis
folderpath <- here(datafoldersinproject1, datafoldersinproject2,projectdatafolder,listofdatafolders[i])
filename <- datafilepaths[j]
## Run Function - N.B. Warnings will appear to tell you that the new directory for data storage already exists. Safe to ignore.
coulbourn_processdata_Operant_SessionTimeBinAnalysis(filename,folderpath,S,timebase, timebinwidth, bin, sessionendstate)
}
# Load Analysis Functions
source(here("scripts", "CoulbournAnalysisFunctions.R"))
for (i in c(1:length(listofdatafolders))){
lookup <- paste(datafoldersinproject1, datafoldersinproject2, projectdatafolder, listofdatafolders[i], sep = "/")
datafilepaths <- list.files(path = lookup, pattern = ".csv")
for (j in c(1:length(datafilepaths))) {
# For each raw.txt file split up the data into individudal subjects .csv files for subsequent analysis
folderpath <- here(datafoldersinproject1, datafoldersinproject2,projectdatafolder,listofdatafolders[i])
filename <- datafilepaths[j]
## Run Function - N.B. Warnings will appear to tell you that the new directory for data storage already exists. Safe to ignore.
coulbourn_processdata_Operant_SessionTimeBinAnalysis(filename,folderpath,S,timebase, timebinwidth, bin, sessionendstate)
}
# Load Analysis Functions
source(here("scripts", "CoulbournAnalysisFunctions.R"))
# Combine all data --------------------------------------------------------
#create list of all filenames
filestojoin <- "0"
for (i in c(1:length(listofdatafolders))){
lookup <- paste(datafoldersinproject1, datafoldersinproject2, projectdatafolder, listofdatafolders[i],"Processed_TimeBin",  sep = "/")
datafilepaths <- list.files(path = lookup, pattern = ".csv", full.names = TRUE)
filestojoin <- c(filestojoin, datafilepaths)
# for (j in c(1:length(datafilepaths))) {
#
#   # For each processed .csv file, load the data and then join it together
#   filename <- datafilepaths[j]
#   ## Load and analyse
}
#delete initialising variable
filestojoin <- filestojoin[-1]
## Load each table of data and join into a single
for (i in c(1:length(filestojoin))){
if (i == 1){
rawdata <- read_csv(filestojoin[i])
} else {
tempdata <- read_csv(filestojoin[i])
rawdata <- full_join(rawdata,tempdata)
}
knitr::opts_chunk$set(echo = FALSE)
## Packages for data organisation and plotting
library(tidyverse)
# Package for relative file paths
library(here)
# library(ggpubr)
library(cowplot)
library(ggsignif)
library(patchwork)
################################################################################
## Packages for Data analysis
library(afex)
afex_options(emmeans_model = "multivariate")# use multivariate model for all follow-up tests.
library(emmeans)
# install.packages("devtools")
# devtools::install_github("crsh/papaja")
library(papaja)
library(knitr)
# remotes::install_github("noamross/redoc")
# library(redoc)
CRF_Acquisition_CSPre <- read_csv(here("figures","figure_data","CRF_Acquisition_CSPre.csv"))
CRF_Acquisition_CSPre_Last5s <- read_csv(here("figures","figure_data","CRF_Acquisition_CSPre_Last5s.csv"))
# Test Data
# CRF_data_P100_HighvsLow_long <- read_csv(here("figures","figure_data","CRF_data_P100_HighvsLow_long.csv"))
# CRF_data_P50_HighvsLow_long <- read_csv(here("figures","figure_data","CRF_data_P50_HighvsLow_long.csv"))
# CRF_data_High_100Vs50_long <- read_csv(here("figures","figure_data","CRF_data_High_100Vs50_long.csv"))
# CRF_data_Low_100Vs50_long <- read_csv(here("figures","figure_data","CRF_data_Low_100Vs50_long.csv"))
CRF_ALL_data_long_Avg <- read_csv(here("figures","figure_data","CRF_ALL_data_long_Avg.csv"))
rawdata <- CRF_Acquisition_CSPre %>%
filter(Period == "CS")
# Stage 1 Acquisition Frequency
anova <- aov_4(MagEntries ~ (Day*CS_name|subject), data = rawdata, anova_table = list(correction = "none", es = "pes"))
anova_Stg1_Freq <- apa_print(anova, mse = "FALSE",correction = "none",es = "pes")
## simple effects - linear trend on Day
simple <- emmeans(anova, ~CS_name)
simple_Stg1_Freq <- apa_print(contrast(simple, interaction = "pairwise", adjust = "tukey"))
anova_Stg1_Freq$table
simple_Stg1_Freq$table
# Stage 1 Acquisition Duration
anova <- aov_4(MagDuration ~ (Day*CS_name|subject), data = rawdata, anova_table = list(correction = "none", es = "pes"))
anova_Stg1_Dur <- apa_print(anova, mse = "FALSE",correction = "none",es = "pes")
## simple effects - linear trend on Day
simple <- emmeans(anova, ~CS_name)
simple_Stg1_Dur <- apa_print(contrast(simple, interaction = "pairwise", adjust = "tukey"))
anova_Stg1_Dur$table
simple_Stg1_Dur$table
rawdata <- CRF_Acquisition_CSPre %>%
filter(Period == "CS",
Day < 7)
# Stage 1 Acquisition Frequency
anova <- aov_4(MagEntries ~ (Day*magnitude*probability|subject), data = rawdata, anova_table = list(correction = "none", es = "pes"))
anova_Stg1_Freq <- apa_print(anova, mse = "FALSE",correction = "none",es = "pes")
## simple effects - linear trend on Day
simple <- emmeans(anova, ~Day*probability)
simple_Stg1_Freq <- apa_print(contrast(simple, interaction = "poly", by = "probability", adjust = "tukey"))
anova_Stg1_Freq$table
simple_Stg1_Freq$table
# Stage 1 Acquisition Duration
anova <- aov_4(MagDuration ~ (Day*magnitude*probability|subject), data = rawdata, anova_table = list(correction = "none", es = "pes"))
anova_Stg1_Dur <- apa_print(anova, mse = "FALSE",correction = "none",es = "pes")
## simple effects - linear trend on Day
simple <- emmeans(anova, ~Day*probability)
simple_Stg1_Dur <- apa_print(contrast(simple, interaction = "pairwise", by = "Day", adjust = "tukey"))
anova_Stg1_Dur$table
simple_Stg1_Dur$table
rawdata <- CRF_Acquisition_CSPre_Last5s %>%
filter(Period == "CS",
Day < 7)
# Stage 1 Acquisition Frequency
anova <- aov_4(MagEntries ~ (Day*CS_name|subject), data = rawdata, anova_table = list(correction = "none", es = "pes"))
anova_Stg1_Freq_5s <- apa_print(anova, mse = "FALSE",correction = "none",es = "pes")
## simple effects - linear trend on Day
simple <- emmeans(anova, ~CS_name)
simple_Stg1_Freq_5s <- apa_print(contrast(simple, interaction = "pairwise", adjust = "tukey"))
anova_Stg1_Freq_5s$table
simple_Stg1_Freq_5s$table
# Stage 1 Acquisition Duration
anova <- aov_4(MagDuration ~ (Day*CS_name|subject), data = rawdata, anova_table = list(correction = "none", es = "pes"))
anova_Stg1_Dur_5s <- apa_print(anova, mse = "FALSE",correction = "none",es = "pes")
## simple effects - linear trend on Day
simple <- emmeans(anova, ~CS_name)
simple_Stg1_Dur_5s <- apa_print(contrast(simple, interaction = "pairwise", adjust = "tukey"))
anova_Stg1_Dur_5s$table
simple_Stg1_Dur_5s$table
rawdata <- CRF_Acquisition_CSPre_Last5s %>%
filter(Period == "CS")
# Stage 1 Acquisition Frequency
anova <- aov_4(MagEntries ~ (Day*magnitude*probability|subject), data = rawdata, anova_table = list(correction = "none", es = "pes"))
anova_Stg1_Freq_5s <- apa_print(anova, mse = "FALSE",correction = "none",es = "pes")
## simple effects - linear trend on Day
simple <- emmeans(anova, ~magnitude*probability)
simple_Stg1_Freq_5s <- apa_print(contrast(simple, interaction = "pairwise", by = "probability", adjust = "tukey"))
anova_Stg1_Freq_5s$table
simple_Stg1_Freq_5s$table
# Stage 1 Acquisition Duration
anova <- aov_4(MagDuration ~ (Day*magnitude*probability|subject), data = rawdata, anova_table = list(correction = "none", es = "pes"))
anova_Stg1_Dur_5s <- apa_print(anova, mse = "FALSE",correction = "none",es = "pes")
## simple effects - linear trend on Day
simple <- emmeans(anova, ~magnitude*probability)
simple_Stg1_Dur_5s <- apa_print(contrast(simple, interaction = "pairwise",  by = "probability", adjust = "tukey"))
anova_Stg1_Dur_5s$table
simple_Stg1_Dur_5s$table
rawdata <- CRF_Acquisition_CSPre %>%
filter(Period == "CS",
Day >= 21)
# Stage 1 Acquisition Frequency
anova <- aov_4(MagEntries ~ (Day*magnitude*probability|subject), data = rawdata, anova_table = list(correction = "none", es = "pes"))
anova_Stg3_Freq <- apa_print(anova, mse = "FALSE",correction = "none",es = "pes")
## simple effects - linear trend on Day
simple <- emmeans(anova, ~magnitude*probability)
simple_Stg3_Freq <- apa_print(contrast(simple, interaction = "pairwise", by = "probability", adjust = "tukey"))
anova_Stg3_Freq$table
simple_Stg3_Freq$table
# Stage 1 Acquisition Duration
anova <- aov_4(MagDuration ~ (Day*magnitude*probability|subject), data = rawdata, anova_table = list(correction = "none", es = "pes"))
anova_Stg3_Dur <- apa_print(anova, mse = "FALSE",correction = "none",es = "pes")
## simple effects - linear trend on Day
simple <- emmeans(anova, ~Day*magnitude)
simple_Stg3_Dur <- apa_print(contrast(simple, interaction = "pairwise", by = "Day", adjust = "tukey"))
anova_Stg3_Dur$table
simple_Stg3_Dur$table
anova_Stg3_Freq$table
simple_Stg3_Freq$table
simple_Stg3_Freq <- apa_print(contrast(simple, interaction = "pairwise", by = "magnitude", adjust = "tukey"))
anova_Stg3_Freq$table
simple_Stg3_Freq$table
simple_Stg3_Freq <- apa_print(contrast(simple, interaction = "pairwise", by = "probability", adjust = "tukey"))
## simple effects - linear trend on Day
simple <- emmeans(anova, ~magnitude*probability)
simple_Stg3_Freq <- apa_print(contrast(simple, interaction = "pairwise", by = "probability", adjust = "tukey"))
simple_Stg3_Freq$table
simple_Stg3_Freq <- apa_print(contrast(simple, interaction = "pairwise", by = "magnitude", adjust = "tukey"))
anova_Stg3_Freq$table
simple_Stg3_Freq$table
anova_Stg3_Freq$table
#  extract processed data filenames, only .csv and put them into a --------
########## Set parameters ############
## List of states
S = c("Test_NonReinforced" = 1,
"RetractedLevers" = 2,
"Test_Reinforced" = 3,
"Flash" = 4,
"Steady" = 5,
"End" = 6,
"Banana" = 8,
"Test_Banana" = 9,
"Chocolate" = 10,
"Test_Chocolate" = 11)
## Time base the linc was set to, in ms
timebase = 20
## Time bins to analyze each state in, in s
timebinwidth = 60
## Count the frequency and duration of these states
bin = c(S["Flash"], S["Steady"])
## state that should be considered the end of the session. For the absolute end of recording specify the number -1 [the state_ID of the finished state in Coulbourn]
sessionendstate <- S["End"]
########## Run Analysis ############
for (i in c(1:length(listofdatafolders))){
lookup <- paste(datafoldersinproject1, datafoldersinproject2, projectdatafolder, listofdatafolders[i], sep = "/")
datafilepaths <- list.files(path = lookup, pattern = ".csv")
for (j in c(1:length(datafilepaths))) {
# For each raw.txt file split up the data into individudal subjects .csv files for subsequent analysis
folderpath <- here(datafoldersinproject1, datafoldersinproject2,projectdatafolder,listofdatafolders[i])
filename <- datafilepaths[j]
## Run Function - N.B. Warnings will appear to tell you that the new directory for data storage already exists. Safe to ignore.
coulbourn_processdata_Operant_SessionTimeBinAnalysis(filename,folderpath,S,timebase, timebinwidth, bin, sessionendstate)
}
# Load Packagaes ----------------------------------------------------------
## Packages for data organisation and plotting
library(tidyverse)
library(knitr)
# Package for relative file paths
library(here)
# Load Analysis Functions
source(here("scripts", "CoulbournAnalysisFunctions.R"))
# Identify files to analyze
# Can't use here() function effectively here, so have to create relative file paths
## COllapses multiple subfolders if needed
datafoldersinproject1 <- c("rawdata")
datafoldersinproject2 <-c("Marios")
## Project specific folder
projectdatafolder <- c("3_LeverPressingForLights")
## Final level of folders contianing the relevant .txt Coulbourn files
listofdatafolders <- c("LPL_Reinstatement_Test_Day15")
#  extract data filenames, only .txt --------------------------------------
datafilepaths <-0
for (i in c(1:length(listofdatafolders))){
lookup <- paste(datafoldersinproject1, datafoldersinproject2, projectdatafolder, listofdatafolders[i], sep = "/")
datafilepaths <- list.files(path = lookup, pattern = ".txt")
for (j in c(1:length(datafilepaths))) {
# For each raw.txt file split up the data into indivudal subjects .csv files for subsequent analysis
folderpath <- here(datafoldersinproject1, datafoldersinproject2,projectdatafolder,listofdatafolders[i])
filename <- datafilepaths[j]
## Run Function
coulbourn_rawdatasplit(filename,folderpath)
}
#  extract processed data filenames, only .csv and put them into a --------
########## Set parameters ############
## List of states
S = c("Test_NonReinforced" = 1,
"RetractedLevers" = 2,
"Test_Reinforced" = 3,
"Flash" = 4,
"Steady" = 5,
"End" = 6,
"Banana" = 8,
"Test_Banana" = 9,
"Chocolate" = 10,
"Test_Chocolate" = 11)
## Time base the linc was set to, in ms
timebase = 20
## Time bins to analyze each state in, in s
timebinwidth = 60
## Count the frequency and duration of these states
bin = c(S["Flash"], S["Steady"])
## state that should be considered the end of the session. For the absolute end of recording specify the number -1 [the state_ID of the finished state in Coulbourn]
sessionendstate <- S["End"]
########## Run Analysis ############
for (i in c(1:length(listofdatafolders))){
lookup <- paste(datafoldersinproject1, datafoldersinproject2, projectdatafolder, listofdatafolders[i], sep = "/")
datafilepaths <- list.files(path = lookup, pattern = ".csv")
for (j in c(1:length(datafilepaths))) {
# For each raw.txt file split up the data into individudal subjects .csv files for subsequent analysis
folderpath <- here(datafoldersinproject1, datafoldersinproject2,projectdatafolder,listofdatafolders[i])
filename <- datafilepaths[j]
## Run Function - N.B. Warnings will appear to tell you that the new directory for data storage already exists. Safe to ignore.
coulbourn_processdata_Operant_SessionTimeBinAnalysis(filename,folderpath,S,timebase, timebinwidth, bin, sessionendstate)
}
# Combine all data --------------------------------------------------------
#create list of all filenames
filestojoin <- "0"
for (i in c(1:length(listofdatafolders))){
lookup <- paste(datafoldersinproject1, datafoldersinproject2, projectdatafolder, listofdatafolders[i],"Processed_TimeBin",  sep = "/")
datafilepaths <- list.files(path = lookup, pattern = ".csv", full.names = TRUE)
filestojoin <- c(filestojoin, datafilepaths)
# for (j in c(1:length(datafilepaths))) {
#
#   # For each processed .csv file, load the data and then join it together
#   filename <- datafilepaths[j]
#   ## Load and analyse
}
#delete initialising variable
filestojoin <- filestojoin[-1]
## Load each table of data and join into a single
for (i in c(1:length(filestojoin))){
if (i == 1){
rawdata <- read_csv(filestojoin[i])
} else {
tempdata <- read_csv(filestojoin[i])
rawdata <- full_join(rawdata,tempdata)
}
# Recode COunterbalancing information -----------------------------------
## Solution: create a counterbalancing data frame and then left_join() with the rawdata to match all relevant rows on Subject[Make sure subject is labelled the same in both tables]
subject <- c("17____",
"18____",
"19____",
"20____",
"21____",
"22____",
"42____",
"43____",
"44____",
"23____",
"24____",
"25____")
counterbalancing <- c("A",
"B",
"A",
"B",
"A",
"B",
"A",
"B",
"A",
"B",
"B")
Pavlovian_cbx <-  c("X",
"X",
"Y",
"X",
"Y",
"X",
"Y",
"Y")
sex <- c("F",
"F",
"M",
"F",
"F")
# Create counterbalancing lookup table
lookup_counterbalancing <- data.frame(subject, counterbalancing, Pavlovian_cbx, sex)
# Combine with rawdata
rawdata <- left_join(rawdata, lookup_counterbalancing, by = "subject")
# Add counterbalancing associated with lever->light IDs
counterbalancing <-  c("A",
"A",
"B",
"B")
Pavlovian_cbx <-  c("X",
"Y",
"X",
"Y")
FLash_leverCbx <-  c("Left",
"Left",
"Right",
"Right")
Steady_levercbx <-  c("Right",
"Left",
"Right",
"Left")
Flash_OutcomeID <- c("Chocolate",
"Banana",
"Chocolate",
"Banana")
Steady_OutcomeID <- c("Banana",
"Chocolate",
"Banana",
"Chocolate")
# Create counterbalancing lookup table
lookup_counterbalancing <- data.frame(counterbalancing, Pavlovian_cbx, FLash_leverCbx, Steady_levercbx, Flash_OutcomeID, Steady_OutcomeID)
# Combine with rawdata
rawdata <- left_join(rawdata, lookup_counterbalancing, by = c("counterbalancing", "Pavlovian_cbx"))
# Calculate Session/Day number --------------------------------------------
rawdata <- rawdata %>%
mutate(folder1 = folder) %>%
separate(folder1, c(NA,"Stage","Schedule","Day"))
savefolderpath <- here("rawdata","Marios","3_LeverPressingForLights","CombinedData")
savefilename <- "LPL_ProcessedData_ReinstatamentTest_WithinSession1minBins.csv"
dir.create(savefolderpath, showWarnings = FALSE)
write_csv(rawdata,here(savefolderpath,savefilename))
source('~/GitHub/Marios-temp/NIDA_Expts/Experiments/MPNIDA001_Pilots/scripts/MasterProcessingScript_3_LPL_ReinstatementTest_WithinSessionTimeBins.R', echo=TRUE)
rawdata <- rawdata %>%
mutate(Test_Period = ifelse(timebins <= 10, "NonReinforced",
ifelse(timebins <= 11, "ITI",
ifelse(timebins <= 13, "Reinstatament",
ifelse(timebins <= 23, "Reinstatament_Test",
ifelse(timebins <= 24, "ITI",
ifelse(timebins <= 26, "Reinstatament",
ifelse(timebins <= 36, "Reinstatament_Test",
ifelse(timebins <= 37, "ITI",
ifelse(timebins <= 47, "Reinforced", NA))))))))))
savefolderpath <- here("rawdata","Marios","3_LeverPressingForLights","CombinedData")
savefilename <- "LPL_ProcessedData_ReinstatamentTest_WithinSession1minBins.csv"
dir.create(savefolderpath, showWarnings = FALSE)
write_csv(rawdata,here(savefolderpath,savefilename))
source('~/GitHub/Marios-temp/NIDA_Expts/Experiments/MPNIDA001_Pilots/scripts/MasterProcessingScript_3_LPL_DevaluationTest_WithinSessionTimeBins.R', echo=TRUE)
source('~/GitHub/Marios-temp/NIDA_Expts/Experiments/MPNIDA001_Pilots/scripts/Plot_3_LPL.R', echo=TRUE)
source('~/GitHub/Marios-temp/NIDA_Expts/Experiments/MPNIDA001_Pilots/scripts/MasterProcessingScript_3_LPL_ReinstatementTest_WithinSessionTimeBins.R', echo=TRUE)
write_csv(rawdata,here(savefolderpath,savefilename))
